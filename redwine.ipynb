{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMQbVioPRLbGJutY1o38Hw2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vibhorjoshi/-CHECK/blob/main/redwine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WELCOME TO FULL GUIDE ON K-NEAREST -NEIGHBOR **ðŸ¤©ðŸ˜Ž**"
      ],
      "metadata": {
        "id": "5SpcdnorP6ZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.K-nearest Neighbor, more well known as simply just KNN is a very simple and intuitive machine learning algorithm.\n",
        "\n",
        "2.I wouldn't say it is a very powerful nor efficient one but it is good to keep it in your arsenal just in case.\n",
        "\n",
        "\n",
        "3.As usual, I will show you the mathematics behind this intuitive algorithm and end this off with some written code to illustrate you how the algorithm is made.\n",
        "Now I know I've used the word 'intuitive' twice, but that's for a reason you shall soon see."
      ],
      "metadata": {
        "id": "87oATMxLRU_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. INTRODUCTION \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3s5yxeYfL8nz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I always believe in a top-down approach to learning as you get to learn the basics/big picture before jumping into the tiny details that define this algorithm.\n",
        "\n",
        "Some notable traits of KNN algorithm is as such\n",
        "\n",
        "1.It is sensitive to feature scales\n",
        "\n",
        "2.Can be used for both classification and regression\n",
        "\n",
        "3.Supervised Learning\n",
        "\n",
        "4.Non-parametric\n"
      ],
      "metadata": {
        "id": "ftlKw9HwSv8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWG6jesVMH-R",
        "outputId": "c510b9fe-93ff-4087-ed12-133027466a3f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "Vuimu8C1MUEY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/wineQualityReds (1).csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "NCRCgyqIOmuJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "df.sample(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "CDqEI-u3Ozr6",
        "outputId": "71e623c9-392f-426f-d305-b069483b3637"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      fixed.acidity  volatile.acidity  citric.acid  residual.sugar  chlorides  \\\n",
              "670             6.9             0.400         0.24             2.5      0.083   \n",
              "311             7.9             0.530         0.24             2.0      0.072   \n",
              "465            10.0             0.290         0.40             2.9      0.098   \n",
              "895             7.1             0.590         0.01             2.3      0.080   \n",
              "554            15.5             0.645         0.49             4.2      0.095   \n",
              "1208            7.2             0.360         0.46             2.1      0.074   \n",
              "1123           10.7             0.400         0.37             1.9      0.081   \n",
              "327            10.3             0.440         0.50             4.5      0.107   \n",
              "435            12.3             0.390         0.63             2.3      0.091   \n",
              "803             7.7             0.560         0.08             2.5      0.114   \n",
              "\n",
              "      free.sulfur.dioxide  total.sulfur.dioxide  density    pH  sulphates  \\\n",
              "670                  30.0                  45.0  0.99590  3.26       0.58   \n",
              "311                  15.0                 105.0  0.99600  3.27       0.54   \n",
              "465                  10.0                  26.0  1.00060  3.48       0.91   \n",
              "895                  27.0                  43.0  0.99550  3.42       0.58   \n",
              "554                  10.0                  23.0  1.00315  2.92       0.74   \n",
              "1208                 24.0                  44.0  0.99534  3.40       0.85   \n",
              "1123                 17.0                  29.0  0.99674  3.12       0.65   \n",
              "327                   5.0                  13.0  0.99800  3.28       0.83   \n",
              "435                   6.0                  18.0  1.00040  3.16       0.49   \n",
              "803                  14.0                  46.0  0.99710  3.24       0.66   \n",
              "\n",
              "      alcohol  quality  \n",
              "670      10.0        5  \n",
              "311       9.4        6  \n",
              "465       9.7        5  \n",
              "895      10.7        6  \n",
              "554      11.1        5  \n",
              "1208     11.0        7  \n",
              "1123     11.2        6  \n",
              "327      11.5        5  \n",
              "435       9.5        5  \n",
              "803       9.6        6  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10e843da-0e0d-4a62-9e76-463d122b2064\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed.acidity</th>\n",
              "      <th>volatile.acidity</th>\n",
              "      <th>citric.acid</th>\n",
              "      <th>residual.sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free.sulfur.dioxide</th>\n",
              "      <th>total.sulfur.dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>670</th>\n",
              "      <td>6.9</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.083</td>\n",
              "      <td>30.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>0.99590</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.58</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>7.9</td>\n",
              "      <td>0.530</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.072</td>\n",
              "      <td>15.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>0.99600</td>\n",
              "      <td>3.27</td>\n",
              "      <td>0.54</td>\n",
              "      <td>9.4</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>465</th>\n",
              "      <td>10.0</td>\n",
              "      <td>0.290</td>\n",
              "      <td>0.40</td>\n",
              "      <td>2.9</td>\n",
              "      <td>0.098</td>\n",
              "      <td>10.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1.00060</td>\n",
              "      <td>3.48</td>\n",
              "      <td>0.91</td>\n",
              "      <td>9.7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>895</th>\n",
              "      <td>7.1</td>\n",
              "      <td>0.590</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.080</td>\n",
              "      <td>27.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.99550</td>\n",
              "      <td>3.42</td>\n",
              "      <td>0.58</td>\n",
              "      <td>10.7</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>15.5</td>\n",
              "      <td>0.645</td>\n",
              "      <td>0.49</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0.095</td>\n",
              "      <td>10.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1.00315</td>\n",
              "      <td>2.92</td>\n",
              "      <td>0.74</td>\n",
              "      <td>11.1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1208</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.360</td>\n",
              "      <td>0.46</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.074</td>\n",
              "      <td>24.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99534</td>\n",
              "      <td>3.40</td>\n",
              "      <td>0.85</td>\n",
              "      <td>11.0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1123</th>\n",
              "      <td>10.7</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.37</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.081</td>\n",
              "      <td>17.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.99674</td>\n",
              "      <td>3.12</td>\n",
              "      <td>0.65</td>\n",
              "      <td>11.2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327</th>\n",
              "      <td>10.3</td>\n",
              "      <td>0.440</td>\n",
              "      <td>0.50</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.107</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>3.28</td>\n",
              "      <td>0.83</td>\n",
              "      <td>11.5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>12.3</td>\n",
              "      <td>0.390</td>\n",
              "      <td>0.63</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.091</td>\n",
              "      <td>6.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1.00040</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.49</td>\n",
              "      <td>9.5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>803</th>\n",
              "      <td>7.7</td>\n",
              "      <td>0.560</td>\n",
              "      <td>0.08</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.114</td>\n",
              "      <td>14.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>0.99710</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.66</td>\n",
              "      <td>9.6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10e843da-0e0d-4a62-9e76-463d122b2064')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10e843da-0e0d-4a62-9e76-463d122b2064 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10e843da-0e0d-4a62-9e76-463d122b2064');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, we have 11 total features of wine \n",
        "The target variable is at the right most column called 'quality'.\n",
        "It ranges from 0 to 10 with 10 being the best quality and 0 being the worst."
      ],
      "metadata": {
        "id": "sNdaoxFHTmr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsOR8eiQTrBv",
        "outputId": "85811454-569a-42ab-87ea-af409f533981"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1599 entries, 0 to 1598\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed.acidity         1599 non-null   float64\n",
            " 1   volatile.acidity      1599 non-null   float64\n",
            " 2   citric.acid           1599 non-null   float64\n",
            " 3   residual.sugar        1599 non-null   float64\n",
            " 4   chlorides             1599 non-null   float64\n",
            " 5   free.sulfur.dioxide   1599 non-null   float64\n",
            " 6   total.sulfur.dioxide  1599 non-null   float64\n",
            " 7   density               1599 non-null   float64\n",
            " 8   pH                    1599 non-null   float64\n",
            " 9   sulphates             1599 non-null   float64\n",
            " 10  alcohol               1599 non-null   float64\n",
            " 11  quality               1599 non-null   int64  \n",
            "dtypes: float64(11), int64(1)\n",
            "memory usage: 150.0 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe ()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "3hbEtP9oUO31",
        "outputId": "4ff40c63-a44a-4d7e-9aae-490566ba0445"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       fixed.acidity  volatile.acidity  citric.acid  residual.sugar  \\\n",
              "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
              "mean        8.319637          0.527821     0.270976        2.538806   \n",
              "std         1.741096          0.179060     0.194801        1.409928   \n",
              "min         4.600000          0.120000     0.000000        0.900000   \n",
              "25%         7.100000          0.390000     0.090000        1.900000   \n",
              "50%         7.900000          0.520000     0.260000        2.200000   \n",
              "75%         9.200000          0.640000     0.420000        2.600000   \n",
              "max        15.900000          1.580000     1.000000       15.500000   \n",
              "\n",
              "         chlorides  free.sulfur.dioxide  total.sulfur.dioxide      density  \\\n",
              "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
              "mean      0.087467            15.874922             46.467792     0.996747   \n",
              "std       0.047065            10.460157             32.895324     0.001887   \n",
              "min       0.012000             1.000000              6.000000     0.990070   \n",
              "25%       0.070000             7.000000             22.000000     0.995600   \n",
              "50%       0.079000            14.000000             38.000000     0.996750   \n",
              "75%       0.090000            21.000000             62.000000     0.997835   \n",
              "max       0.611000            72.000000            289.000000     1.003690   \n",
              "\n",
              "                pH    sulphates      alcohol      quality  \n",
              "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
              "mean      3.311113     0.658149    10.422983     5.636023  \n",
              "std       0.154386     0.169507     1.065668     0.807569  \n",
              "min       2.740000     0.330000     8.400000     3.000000  \n",
              "25%       3.210000     0.550000     9.500000     5.000000  \n",
              "50%       3.310000     0.620000    10.200000     6.000000  \n",
              "75%       3.400000     0.730000    11.100000     6.000000  \n",
              "max       4.010000     2.000000    14.900000     8.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9047ec3c-a3fd-4485-b3d2-df8e2f401e73\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed.acidity</th>\n",
              "      <th>volatile.acidity</th>\n",
              "      <th>citric.acid</th>\n",
              "      <th>residual.sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free.sulfur.dioxide</th>\n",
              "      <th>total.sulfur.dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>8.319637</td>\n",
              "      <td>0.527821</td>\n",
              "      <td>0.270976</td>\n",
              "      <td>2.538806</td>\n",
              "      <td>0.087467</td>\n",
              "      <td>15.874922</td>\n",
              "      <td>46.467792</td>\n",
              "      <td>0.996747</td>\n",
              "      <td>3.311113</td>\n",
              "      <td>0.658149</td>\n",
              "      <td>10.422983</td>\n",
              "      <td>5.636023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.741096</td>\n",
              "      <td>0.179060</td>\n",
              "      <td>0.194801</td>\n",
              "      <td>1.409928</td>\n",
              "      <td>0.047065</td>\n",
              "      <td>10.460157</td>\n",
              "      <td>32.895324</td>\n",
              "      <td>0.001887</td>\n",
              "      <td>0.154386</td>\n",
              "      <td>0.169507</td>\n",
              "      <td>1.065668</td>\n",
              "      <td>0.807569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.600000</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.012000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.990070</td>\n",
              "      <td>2.740000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>7.100000</td>\n",
              "      <td>0.390000</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>1.900000</td>\n",
              "      <td>0.070000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.995600</td>\n",
              "      <td>3.210000</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.900000</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.260000</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>0.079000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>0.996750</td>\n",
              "      <td>3.310000</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>10.200000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>9.200000</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>2.600000</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.997835</td>\n",
              "      <td>3.400000</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>11.100000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>15.900000</td>\n",
              "      <td>1.580000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>0.611000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>289.000000</td>\n",
              "      <td>1.003690</td>\n",
              "      <td>4.010000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>14.900000</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9047ec3c-a3fd-4485-b3d2-df8e2f401e73')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9047ec3c-a3fd-4485-b3d2-df8e2f401e73 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9047ec3c-a3fd-4485-b3d2-df8e2f401e73');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of dataframe: {}\".format(df.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDy8zaCwUWDi",
        "outputId": "428aa926-9155-42bc-cd16-e0101082affb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of dataframe: (1599, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, this dataframe is extremely neat and clean in the sense that it doesn't mean any imputation as it has no null values.\n",
        "\n",
        "But one thing you have to remember about this algorithm, as I have mentioned above, \n",
        "is that KNN algorithm is sensitive to feature scaling as it allocates classes depending on the distances.\n",
        "    \n",
        "    Let us go ahead and standardize our features."
      ],
      "metadata": {
        "id": "F6n7qgupUkzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scale = StandardScaler()\n",
        "scaled_df = scale.fit_transform(df) \n",
        "scaled_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrE_tFCqUy44",
        "outputId": "25040f28-7bf6-49d0-8908-7e499272a1b7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.52835961,  0.96187667, -1.39147228, ..., -0.57920652,\n",
              "        -0.96024611, -0.78782264],\n",
              "       [-0.29854743,  1.96744245, -1.39147228, ...,  0.1289504 ,\n",
              "        -0.58477711, -0.78782264],\n",
              "       [-0.29854743,  1.29706527, -1.18607043, ..., -0.04808883,\n",
              "        -0.58477711, -0.78782264],\n",
              "       ...,\n",
              "       [-1.1603431 , -0.09955388, -0.72391627, ...,  0.54204194,\n",
              "         0.54162988,  0.45084835],\n",
              "       [-1.39015528,  0.65462046, -0.77526673, ...,  0.30598963,\n",
              "        -0.20930812, -0.78782264],\n",
              "       [-1.33270223, -1.21684919,  1.02199944, ...,  0.01092425,\n",
              "         0.54162988,  0.45084835]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How about the target variable you may ask"
      ],
      "metadata": {
        "id": "RCxmwtCxVggF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.set(rc={'figure.figsize':(15,7)})\n",
        "sns.countplot('quality', data = df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "jm6PE7VwVlZK",
        "outputId": "25c5244f-ccf2-47ee-8b46-b90eb3832e31"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f66a12f17d0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the majority of the values for quality lies within the 5 to 7 range.\n",
        "\n",
        "There are no 0, 1, 2, 9 or 10 ratings.\n",
        "\n",
        "This obvious imbalance and bias towards the 5 to 7 quality is not the most ideal to our machine learning algorithm.\n",
        "\n",
        "This sampling bias will possibly lead to our model outputting biased results.\n",
        "\n",
        "The ideal case would be to have all the counts for quality spread out as evenly as possible.\n",
        "\n",
        "For the time being, let's just keep this fact at the back of our heads and move on."
      ],
      "metadata": {
        "id": "bXQnj8k3V3Ji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CODE"
      ],
      "metadata": {
        "id": "B9NAMMHsWtxu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alright! Now I will proceed onto show you how the whole algorithm is written from scratch."
      ],
      "metadata": {
        "id": "K0KBWdnrW4ae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# splitting dataset"
      ],
      "metadata": {
        "id": "H317gVIRW9Hs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us first split our dataset.\n",
        "\n",
        "I know I have said that there is not much training to this simple algorithm, \n",
        "\n",
        "but just for convention sake :"
      ],
      "metadata": {
        "id": "DcYbeHbWXU-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled_df[:,:-1], np.array(df.iloc[:,-1]), test_size=0.33, random_state=42)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_grehbbVXggN",
        "outputId": "a5e81313-0396-4acb-aa95-bcfc8dbb906a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1071, 11) (528, 11) (1071,) (528,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've got our training and test sets, let us jump into the actual mechanism of KNN\n"
      ],
      "metadata": {
        "id": "AisG9WkiXprW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2 Calculating Distance"
      ],
      "metadata": {
        "id": "gIhfSEIRX49q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "first, the code for calculating the euclidean distance between two points"
      ],
      "metadata": {
        "id": "uXqkHmixX7um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_dist(a,b):\n",
        "    distance = np.square(a - b) \n",
        "    distance = np.sum(distance)\n",
        "    distance = np.sqrt(distance) \n",
        "    return distance"
      ],
      "metadata": {
        "id": "nl9QoEZ-YBiN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, code for obtaining the distance from the test point to all the other points in the training dataset"
      ],
      "metadata": {
        "id": "cYUG7nB_YRWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def distance_from_all_training(test_point):\n",
        "    dist_array = np.array([])\n",
        "    for train_point in X_train:\n",
        "        dist = euclidean_dist(test_point, train_point)\n",
        "        dist_array = np.append(dist_array,dist)\n",
        "    return dist_array "
      ],
      "metadata": {
        "id": "zCWPZOFhYSiW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Picking out K closest points"
      ],
      "metadata": {
        "id": "hXPhMVJD8BCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the code for combining all of the above into a function that takes in the training dataset\n",
        "\n",
        " A set of test features and the number k."
      ],
      "metadata": {
        "id": "7kSr8_vK8JyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This functino would return us the predictions for each datapoint in the test_feature input."
      ],
      "metadata": {
        "id": "xWZ-C2LJ80zM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def KNNClassifier(train_features, train_target, test_features, k = 10):\n",
        "    predictions = np.array([])\n",
        "    train_target = train_target.reshape(-1,1)\n",
        "    for test_point in test_features: \n",
        "        dist_array = distance_from_all_training(test_point).reshape(-1,1) \n",
        "        neighbors = np.concatenate((dist_array, train_target), axis = 1) \n",
        "        neighbors_sorted = neighbors[neighbors[:, 0].argsort()] \n",
        "        k_neighbors = neighbors_sorted[:k] \n",
        "        frequency = np.unique(k_neighbors[:, 1], return_counts=True)\n",
        "        target_class = frequency[0][frequency[1].argmax()] \n",
        "        predictions = np.append(predictions, target_class)\n",
        "    \n",
        "    return predictions "
      ],
      "metadata": {
        "id": "2Qup4x1x9wh2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ACCURACY"
      ],
      "metadata": {
        "id": "U7XHvBZkHXta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, before jumping in to see how our function works, we got to define our code to check the accuracy of our model.\n",
        "\n",
        "We will come up with a block of code to compare our predictions with the test target features."
      ],
      "metadata": {
        "id": "nTBbT0IHHa2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_test,y_preds):\n",
        "     total_correct=0\n",
        "     for i in range(len(y_test)):\n",
        "       if int(y_test[i])==int(y_preds[i]):\n",
        "         total_correct+=1\n",
        "         acc=total_correct/len(y_test)#getting the proportion \n",
        "         return acc*100"
      ],
      "metadata": {
        "id": "HPU-nN0-Hhge"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Putting it all together "
      ],
      "metadata": {
        "id": "8PcUApFsJ4yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = KNNClassifier(X_train, y_train, X_test, k = 10)"
      ],
      "metadata": {
        "id": "GNnN49BmKAob"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = accuracy(y_test, preds)\n",
        "print('Model accuracy = {:.2f}'.format(acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3fLQEuSLEqR",
        "outputId": "9322f732-11c6-47a4-d6db-cdfd6b87dd64"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy = 0.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
        "model = KNN()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "acc = accuracy(y_test, preds)\n",
        "print('Model accuracy = {:.2f}'.format(acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avQ5t-_2MDfA",
        "outputId": "eb9fe39f-201f-4117-8804-3b2535fa0118"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy = 0.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whao! Do you see that both the accuracies are the same.\n",
        "\n",
        "Although the accuracy is not that great to start off with, we can't blame our code for it since the Sklearn's one did not fare better.\n",
        "\n",
        "Let us take one additional step and see how the random forest algorithm fares for this dataset."
      ],
      "metadata": {
        "id": "uhqaeAyJNgCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train,y_train)\n",
        "\n",
        "preds = rf.predict(X_test)\n",
        "\n",
        "acc = accuracy(y_test,preds)\n",
        "print('Model accuracy = {:.2f}'.format(acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Nwu1tnoNlhR",
        "outputId": "9aab315c-536f-4c2f-f5f2-e7561b4b3ed0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy = 0.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3E3aMulHN3vz"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}